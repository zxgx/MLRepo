{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from implemention.utils.load import *\n",
    "\n",
    "X_train, y_train, X_val, y_val = load_train_data()\n",
    "# test = load_test_data()\n",
    "#X_train, y_train = X_train[:2000], y_train[:2000]\n",
    "#X_val, y_val = X_val[:500], y_val[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "num_classes = 7\n",
    "\n",
    "tar_train, tar_val = y_train, y_val\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pre, y_pre = X_train[:2000], y_train[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 4709 samples\n",
      "Epoch 1/25\n",
      "24000/24000 [==============================] - 483s 20ms/step - loss: 3.2771 - acc: 0.2018 - val_loss: 2.5901 - val_acc: 0.2729\n",
      "Epoch 2/25\n",
      "24000/24000 [==============================] - 417s 17ms/step - loss: 2.3888 - acc: 0.2495 - val_loss: 2.1622 - val_acc: 0.2659\n",
      "Epoch 3/25\n",
      "24000/24000 [==============================] - 418s 17ms/step - loss: 1.9217 - acc: 0.3435 - val_loss: 1.7970 - val_acc: 0.3619\n",
      "Epoch 4/25\n",
      "24000/24000 [==============================] - 425s 18ms/step - loss: 1.6733 - acc: 0.4040 - val_loss: 1.9215 - val_acc: 0.3219\n",
      "Epoch 5/25\n",
      "24000/24000 [==============================] - 416s 17ms/step - loss: 1.5596 - acc: 0.4358 - val_loss: 1.7182 - val_acc: 0.3763\n",
      "Epoch 6/25\n",
      "24000/24000 [==============================] - 420s 18ms/step - loss: 1.5001 - acc: 0.4582 - val_loss: 1.6738 - val_acc: 0.3761\n",
      "Epoch 7/25\n",
      "24000/24000 [==============================] - 428s 18ms/step - loss: 1.4632 - acc: 0.4753 - val_loss: 1.6824 - val_acc: 0.3941\n",
      "Epoch 8/25\n",
      "24000/24000 [==============================] - 433s 18ms/step - loss: 1.4288 - acc: 0.4913 - val_loss: 1.6622 - val_acc: 0.3999\n",
      "Epoch 9/25\n",
      "24000/24000 [==============================] - 440s 18ms/step - loss: 1.4134 - acc: 0.5003 - val_loss: 1.5471 - val_acc: 0.4328\n",
      "Epoch 10/25\n",
      "24000/24000 [==============================] - 431s 18ms/step - loss: 1.3898 - acc: 0.5061 - val_loss: 1.7479 - val_acc: 0.3410\n",
      "Epoch 11/25\n",
      "24000/24000 [==============================] - 436s 18ms/step - loss: 1.3749 - acc: 0.5186 - val_loss: 1.5057 - val_acc: 0.4568\n",
      "Epoch 12/25\n",
      "24000/24000 [==============================] - 430s 18ms/step - loss: 1.3709 - acc: 0.5191 - val_loss: 1.5184 - val_acc: 0.4555\n",
      "Epoch 13/25\n",
      "24000/24000 [==============================] - 431s 18ms/step - loss: 1.3587 - acc: 0.5294 - val_loss: 1.5327 - val_acc: 0.4547\n",
      "Epoch 14/25\n",
      "24000/24000 [==============================] - 423s 18ms/step - loss: 1.3492 - acc: 0.5338 - val_loss: 1.6768 - val_acc: 0.4082\n",
      "Epoch 15/25\n",
      "24000/24000 [==============================] - 412s 17ms/step - loss: 1.3436 - acc: 0.5362 - val_loss: 1.6834 - val_acc: 0.3839\n",
      "Epoch 16/25\n",
      "24000/24000 [==============================] - 421s 18ms/step - loss: 1.3332 - acc: 0.5430 - val_loss: 1.4605 - val_acc: 0.4863\n",
      "Epoch 17/25\n",
      "24000/24000 [==============================] - 410s 17ms/step - loss: 1.3194 - acc: 0.5493 - val_loss: 1.4944 - val_acc: 0.4835\n",
      "Epoch 18/25\n",
      "24000/24000 [==============================] - 405s 17ms/step - loss: 1.3100 - acc: 0.5524 - val_loss: 1.3694 - val_acc: 0.5256\n",
      "Epoch 19/25\n",
      "24000/24000 [==============================] - 405s 17ms/step - loss: 1.3085 - acc: 0.5568 - val_loss: 1.4827 - val_acc: 0.4765\n",
      "Epoch 20/25\n",
      "24000/24000 [==============================] - 401s 17ms/step - loss: 1.3009 - acc: 0.5576 - val_loss: 1.4857 - val_acc: 0.5044\n",
      "Epoch 21/25\n",
      "12600/24000 [==============>...............] - ETA: 3:01 - loss: 1.2890 - acc: 0.5647"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(1, 48, 48),\n",
    "                 data_format='channels_first', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_first', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first')) #24\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_first', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_first', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first')) #12\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_first', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same', data_format='channels_first', kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_first')) #6\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# affine -> relu -> dropout * 1\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))df\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(500))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(300))\n",
    "model.add(BatchNormalization(axis=1, momentum=0.99, epsilon=1e-5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optim = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
    "#optim = keras.optimizers.SGD(lr=0.001, momentum=0.95, decay=0.0)\n",
    "#optim = keras.optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=200, epochs=25, validation_data=(X_val, y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_set = load_test_data()\n",
    "res = model.predict(test_set, verbose=1)\n",
    "pred = np.argmax(res, axis=1)\n",
    "\n",
    "d1 = np.arange(pred.shape[0]).reshape(-1,1)\n",
    "d2 = pred.reshape(-1,1)\n",
    "d = np.hstack((d1, d2))\n",
    "df = pd.DataFrame(d, columns=['id', 'label'])\n",
    "df.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[conv->batchnorm->relu->conv->batchnorm->relu->2*2maxpool]*3->[affine->batchnorm->relu->dropout]*2->affine->softmax\n",
    "Test accuracy: 0.4835421533265876\n",
    "\n",
    "Test accuracy: 0.5185814397992995\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py368_for_ml",
   "language": "python",
   "name": "py368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
